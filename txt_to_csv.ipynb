{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27714c9b-ab4f-4906-856b-7901dc24cf77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path to your text file\n",
    "# file_path = r'C:\\Users\\prs90\\Downloads\\tranmitter_uplane_prb_fields_frame_117.txt'\n",
    "# a=[]\n",
    "# b=[]\n",
    "# # Function to extract iSample and qSample values from a text file\n",
    "# def extract_samples(file_path):\n",
    "#     i_samples = []\n",
    "#     q_samples = []\n",
    "\n",
    "#     with open(file_path, 'r') as file:\n",
    "#         for line in file:\n",
    "#             if \"iSample:\" in line:\n",
    "#                 # Extract the iSample value\n",
    "#                 sample_value = line.split(':')[1].strip()\n",
    "#                 i_samples.append(sample_value)\n",
    "#             elif \"qSample:\" in line:\n",
    "#                 # Extract the qSample value\n",
    "#                 sample_value = line.split(':')[1].strip()\n",
    "#                 q_samples.append(sample_value)\n",
    "\n",
    "#     return i_samples, q_samples\n",
    "    \n",
    "# # Call the function and print results\n",
    "# i_samples, q_samples = extract_samples(file_path)\n",
    "\n",
    "# for i in range(0,len(i_samples)):\n",
    "#     a.append(i_samples[i][:12])\n",
    "# for i in range(0,len(q_samples)):\n",
    "#     b.append(q_samples[i][:12])\n",
    "# # Create a new DataFrame from the list\n",
    "# isa = pd.DataFrame([a])  # Use [i_samples] to create a single row\n",
    "\n",
    "# # Rename columns to i_samples_n\n",
    "# isa.columns = [f'i_samples_{i}' for i in range(len(a))]\n",
    "# # Create a new DataFrame from the list\n",
    "# qsa = pd.DataFrame([b])  # Use [i_samples] to create a single row\n",
    "\n",
    "# # Rename columns to i_samples_n\n",
    "# qsa.columns = [f'q_samples_{i}' for i in range(len(b))]\n",
    "# final=pd.concat([isa,qsa],axis=1)\n",
    "# final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d335021-d0b5-4519-a81e-923576736e7b",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Cannot run the event loop while another loop is running",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 90\u001b[0m\n\u001b[0;32m     87\u001b[0m output_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mRahul Singh\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDocuments\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mpacap_project\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;66;03m# Process the PCAP file and generate text files for each frame\u001b[39;00m\n\u001b[1;32m---> 90\u001b[0m process_pcap_files(pcap_file, output_dir)\n\u001b[0;32m     92\u001b[0m \u001b[38;5;66;03m# Define the output CSV file\u001b[39;00m\n\u001b[0;32m     93\u001b[0m csv_output_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mRahul Singh\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDocuments\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mpacap_project\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mfinal_output.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "Cell \u001b[1;32mIn[5], line 14\u001b[0m, in \u001b[0;36mprocess_pcap_files\u001b[1;34m(pcap_file, output_dir)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess_pcap_files\u001b[39m(pcap_file, output_dir):\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;66;03m# Open the PCAP file\u001b[39;00m\n\u001b[0;32m     12\u001b[0m     capture \u001b[38;5;241m=\u001b[39m pyshark\u001b[38;5;241m.\u001b[39mFileCapture(pcap_file)\n\u001b[1;32m---> 14\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m packet \u001b[38;5;129;01min\u001b[39;00m capture:\n\u001b[0;32m     15\u001b[0m         \u001b[38;5;66;03m# Create a unique filename for each frame\u001b[39;00m\n\u001b[0;32m     16\u001b[0m         frame_file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_dir, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mframe_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpacket\u001b[38;5;241m.\u001b[39mnumber\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     17\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(frame_file_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m output_file:\n",
      "File \u001b[1;32mc:\\Users\\Rahul Singh\\anaconda3\\Lib\\site-packages\\pyshark\\capture\\capture.py:212\u001b[0m, in \u001b[0;36mCapture._packets_from_tshark_sync\u001b[1;34m(self, packet_count, existing_process)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns a generator of packets.\u001b[39;00m\n\u001b[0;32m    205\u001b[0m \n\u001b[0;32m    206\u001b[0m \u001b[38;5;124;03mThis is the sync version of packets_from_tshark. It wait for the completion of each coroutine and\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[38;5;124;03m:param packet_count: If given, stops after this amount of packets is captured.\u001b[39;00m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    211\u001b[0m \u001b[38;5;66;03m# NOTE: This has code duplication with the async version, think about how to solve this\u001b[39;00m\n\u001b[1;32m--> 212\u001b[0m tshark_process \u001b[38;5;241m=\u001b[39m existing_process \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meventloop\u001b[38;5;241m.\u001b[39mrun_until_complete(\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tshark_process())\n\u001b[0;32m    214\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setup_tshark_output_parser()\n\u001b[0;32m    215\u001b[0m packets_captured \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Rahul Singh\\anaconda3\\Lib\\asyncio\\base_events.py:663\u001b[0m, in \u001b[0;36mBaseEventLoop.run_until_complete\u001b[1;34m(self, future)\u001b[0m\n\u001b[0;32m    652\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Run until the Future is done.\u001b[39;00m\n\u001b[0;32m    653\u001b[0m \n\u001b[0;32m    654\u001b[0m \u001b[38;5;124;03mIf the argument is a coroutine, it is wrapped in a Task.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    660\u001b[0m \u001b[38;5;124;03mReturn the Future's result, or raise its exception.\u001b[39;00m\n\u001b[0;32m    661\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    662\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[1;32m--> 663\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_running()\n\u001b[0;32m    665\u001b[0m new_task \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m futures\u001b[38;5;241m.\u001b[39misfuture(future)\n\u001b[0;32m    666\u001b[0m future \u001b[38;5;241m=\u001b[39m tasks\u001b[38;5;241m.\u001b[39mensure_future(future, loop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Rahul Singh\\anaconda3\\Lib\\asyncio\\base_events.py:624\u001b[0m, in \u001b[0;36mBaseEventLoop._check_running\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    622\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThis event loop is already running\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    623\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m events\u001b[38;5;241m.\u001b[39m_get_running_loop() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 624\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    625\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCannot run the event loop while another loop is running\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Cannot run the event loop while another loop is running"
     ]
    }
   ],
   "source": [
    "import pyshark\n",
    "import pandas as pd\n",
    "import os\n",
    "import nest_asyncio\n",
    "\n",
    "# Allow multiple asyncio event loops\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Function to process the PCAP file and write the output to text files\n",
    "def process_pcap_files(pcap_file, output_dir):\n",
    "    # Open the PCAP file\n",
    "    capture = pyshark.FileCapture(pcap_file)\n",
    "    \n",
    "    for packet in capture:\n",
    "        # Create a unique filename for each frame\n",
    "        frame_file_path = os.path.join(output_dir, f\"frame_{packet.number}.txt\")\n",
    "        with open(frame_file_path, \"w\") as output_file:\n",
    "            output_file.write(f\"\\n--- Frame {packet.number} ---\\n\")\n",
    "            \n",
    "            # O-RAN Fronthaul CUS fields\n",
    "            oran_layer = getattr(packet, 'oran_fh_cus', None)\n",
    "            if oran_layer:\n",
    "                output_file.write(f\"Oran layer: {oran_layer}\\n\")\n",
    "                # Extract specific fields from the O-RAN Fronthaul CUS layer\n",
    "                if hasattr(oran_layer, 'fields'):\n",
    "                    for field in oran_layer.fields:\n",
    "                        output_file.write(f\"{field.name}: {field.showname_value}\\n\")\n",
    "    print(f\"PCAP processed and text files saved in {output_dir}.\")\n",
    "\n",
    "# Function to extract iSample and qSample values from a text file\n",
    "def extract_samples(file_path):\n",
    "    i_samples = []\n",
    "    q_samples = []\n",
    "\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            if \"iSample:\" in line:\n",
    "                # Extract the iSample value\n",
    "                sample_value = line.split(':')[1].strip()\n",
    "                i_samples.append(sample_value)\n",
    "            elif \"qSample:\" in line:\n",
    "                # Extract the qSample value\n",
    "                sample_value = line.split(':')[1].strip()\n",
    "                q_samples.append(sample_value)\n",
    "\n",
    "    return i_samples, q_samples\n",
    "\n",
    "# Function to process all text files and save results into a CSV\n",
    "def process_text_files_and_save_csv(output_dir, csv_output_file):\n",
    "    all_i_samples = []\n",
    "    all_q_samples = []\n",
    "    \n",
    "    # Iterate through all text files in the directory\n",
    "    for file_name in os.listdir(output_dir):\n",
    "        if file_name.endswith(\".txt\"):\n",
    "            file_path = os.path.join(output_dir, file_name)\n",
    "            i_samples, q_samples = extract_samples(file_path)\n",
    "\n",
    "            # Extract the first 12 characters for iSamples and qSamples\n",
    "            a = [i_sample[:12] for i_sample in i_samples]\n",
    "            b = [q_sample[:12] for q_sample in q_samples]\n",
    "\n",
    "            # Append extracted values to the lists\n",
    "            all_i_samples.append(a)\n",
    "            all_q_samples.append(b)\n",
    "    \n",
    "    # Create DataFrames for i_samples and q_samples\n",
    "    isa = pd.DataFrame(all_i_samples)  # Multiple rows for i_samples\n",
    "    isa.columns = [f'i_samples_{i}' for i in range(isa.shape[1])]\n",
    "\n",
    "    qsa = pd.DataFrame(all_q_samples)  # Multiple rows for q_samples\n",
    "    qsa.columns = [f'q_samples_{i}' for i in range(qsa.shape[1])]\n",
    "\n",
    "    # Concatenate i_samples and q_samples into a single DataFrame\n",
    "    final_df = pd.concat([isa, qsa], axis=1)\n",
    "\n",
    "    # Save the final DataFrame to a CSV file\n",
    "    final_df.to_csv(csv_output_file, index=False)\n",
    "    print(f\"Data saved to {csv_output_file}\")\n",
    "\n",
    "# Main code\n",
    "if __name__ == \"__main__\":\n",
    "    # Define the path to the PCAP file\n",
    "    pcap_file = r\"C:\\Users\\Rahul Singh\\Documents\\pacap_project\\transmitter_uplane_dl_only_5g_nr2_1cc_400MHz_TM1p1_10ms_4pcap.pcap\"\n",
    "    \n",
    "    # Define the output directory for text files\n",
    "    output_dir = r\"C:\\Users\\Rahul Singh\\Documents\\pacap_project\\output\"\n",
    "    \n",
    "    # Process the PCAP file and generate text files for each frame\n",
    "    process_pcap_files(pcap_file, output_dir)\n",
    "    \n",
    "    # Define the output CSV file\n",
    "    csv_output_file = r\"C:\\Users\\Rahul Singh\\Documents\\pacap_project\\output\\final_output.csv\"\n",
    "    \n",
    "    # Process all text files and save the extracted iSample and qSample values to a CSV file\n",
    "    process_text_files_and_save_csv(output_dir, csv_output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0a7880",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
